# ğŸŒ¾ AI-Powered Crop Recommendation System

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.0-orange.svg)](https://scikit-learn.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **An intelligent crop recommendation system using ensemble machine learning models with explainable AI capabilities for sustainable agriculture decision-making.**

---

## ğŸ“‹ Table of Contents

- [Project Overview](#-project-overview)
- [Key Features](#-key-features)
- [Project Status](#-project-status)
- [Technology Stack](#-technology-stack)
- [Project Structure](#-project-structure)
- [Datasets](#-datasets)
- [Model Performance](#-model-performance)
- [Installation](#-installation)
- [Usage](#-usage)
- [Notebooks Guide](#-notebooks-guide)
- [Future Roadmap](#-future-roadmap)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Project Overview

This semester project develops an advanced crop recommendation system that goes beyond traditional ML predictions by incorporating:

1. **Multiple ML Models** - Logistic Regression, Decision Tree, Random Forest, SVM
2. **Comprehensive EDA** - 43+ visualizations for data understanding
3. **Feature Engineering** - 39 engineered features from 7 original features
4. **Model Comparison** - Systematic comparison of all trained models
5. **Production-Ready Models** - Saved as pickle files for deployment

### Problem Statement

Farmers often struggle to select the optimal crop for their land based on soil conditions and climate. This system provides data-driven recommendations to maximize yield and profitability.

### Research Alignment

This project aligns with academic curriculum covering:
- **Unit I**: Data Collection, Cleaning, Preprocessing
- **Unit II**: Exploratory Data Analysis, Statistical Analysis
- **Unit III**: Supervised Classification Algorithms
- **Unit IV**: Ensemble Methods, Model Evaluation

---

## âœ¨ Key Features

| Feature | Description | Status |
|---------|-------------|--------|
| ğŸ”¬ **Data Pipeline** | Complete ETL from raw data to ML-ready features | âœ… Complete |
| ğŸ“Š **EDA & Visualization** | 43 comprehensive plots and charts | âœ… Complete |
| ğŸ¤– **Multiple ML Models** | 4 different classification algorithms | âœ… Complete |
| ğŸ“ˆ **Model Comparison** | Performance metrics across all models | âœ… Complete |
| ğŸ¯ **High Accuracy** | Up to 99.32% test accuracy (Random Forest) | âœ… Achieved |
| ğŸ”§ **Feature Engineering** | 39 features from original 7 | âœ… Complete |
| ğŸ’¾ **Model Persistence** | All models saved as .pkl files | âœ… Complete |
| ğŸŒ **Web Application** | Flask-based prediction interface | â³ Planned |
| ğŸ“– **Explainable AI** | SHAP-based explanations | â³ Planned |
| ğŸ’° **Economic Analysis** | ROI calculations for crops | â³ Planned |

---

## ğŸ“Š Project Status

### âœ… Completed Components

| Component | Files | Description |
|-----------|-------|-------------|
| **Notebooks** | 9 notebooks | Data pipeline + 4 ML models |
| **Models** | 4 trained models | LR, DT, RF, SVM |
| **Visualizations** | 43 plots | EDA + Model performance |
| **Processed Data** | 22+ files | Cleaned, engineered, ML-ready |
| **Results** | 17 files | Reports, predictions, comparisons |

### â³ Planned Components

| Component | Status | Priority |
|-----------|--------|----------|
| XGBoost Model | Not Started | High |
| LightGBM Model | Not Started | High |
| Stacking Ensemble | Not Started | High |
| SHAP Explainability | Not Started | Medium |
| Economic Analysis | Not Started | Medium |
| Flask Web App | Not Started | Medium |
| Crop Rotation Planning | Not Started | Low |

---

## ğŸ› ï¸ Technology Stack

### Core Technologies
| Category | Technologies |
|----------|-------------|
| **Language** | Python 3.10+ |
| **Notebooks** | Jupyter Notebook 7.0.6 |
| **Data Science** | Pandas 2.1.0, NumPy 1.24.3 |
| **Machine Learning** | scikit-learn 1.3.0 |
| **Visualization** | Matplotlib 3.7.2, Seaborn 0.12.2, Plotly 5.16.1 |
| **Statistics** | SciPy 1.11.2 |
| **Web Framework** | Flask 3.0.0 (planned) |

### Planned Technologies
| Category | Technologies |
|----------|-------------|
| **Boosting** | XGBoost 1.7.6, LightGBM 4.0.0 |
| **Explainability** | SHAP 0.42.1 |

---

## ğŸ“ Project Structure

```
crop-recommendation-system/
â”‚
â”œâ”€â”€ ğŸ““ notebooks/                          # Jupyter Notebooks (9 implemented)
â”‚   â”œâ”€â”€ 01_Data_Collection_and_Loading.ipynb
â”‚   â”œâ”€â”€ 2.Data Cleaning and Preprocessing.ipynb
â”‚   â”œâ”€â”€ 3.Exploratory Data Analysis.ipynb
â”‚   â”œâ”€â”€ 4.Feature Engineering.ipynb
â”‚   â”œâ”€â”€ 5.Train Test Split and Preparation.ipynb
â”‚   â”œâ”€â”€ 6.Model Training Logistic Regression.ipynb
â”‚   â”œâ”€â”€ 7.Model Training Decision Tree.ipynb
â”‚   â”œâ”€â”€ 8.Model Training Random Forest.ipynb
â”‚   â””â”€â”€ 9.Model Training SVM.ipynb
â”‚
â”œâ”€â”€ ğŸ“Š data/
â”‚   â”œâ”€â”€ raw/                               # Original datasets (6 files)
â”‚   â”‚   â”œâ”€â”€ Crop_recommendation.csv       # Primary dataset (2,200 rows)
â”‚   â”‚   â”œâ”€â”€ Crop and fertilizer dataset.csv
â”‚   â”‚   â”œâ”€â”€ rotation_rules.csv            # 343 rotation combinations
â”‚   â”‚   â”œâ”€â”€ crop-area-and-production.xlsx
â”‚   â”‚   â””â”€â”€ Season_Price_Arrival_*.csv    # Market price data
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                         # Cleaned & transformed (22+ files)
â”‚   â”‚   â”œâ”€â”€ crop_data_cleaned.csv
â”‚   â”‚   â”œâ”€â”€ crop_data_engineered.csv
â”‚   â”‚   â”œâ”€â”€ ml_ready/                     # Train/test splits, scalers
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ results/                           # Model outputs (17 files)
â”‚   â”‚   â”œâ”€â”€ model_comparison_all.csv
â”‚   â”‚   â”œâ”€â”€ *_classification_report.csv
â”‚   â”‚   â”œâ”€â”€ *_predictions.csv
â”‚   â”‚   â””â”€â”€ *_summary.csv
â”‚   â”‚
â”‚   â””â”€â”€ visualizations/                    # Generated plots (43 files)
â”‚       â”œâ”€â”€ 01-23: EDA visualizations
â”‚       â”œâ”€â”€ 24-28: Logistic Regression plots
â”‚       â”œâ”€â”€ 29-33: Decision Tree plots
â”‚       â”œâ”€â”€ 34-39: Random Forest plots
â”‚       â””â”€â”€ 40-43: SVM plots
â”‚
â”œâ”€â”€ ğŸ¤– models/                             # Trained ML Models
â”‚   â”œâ”€â”€ logistic_regression_model.pkl     # ~8 KB
â”‚   â”œâ”€â”€ decision_tree_model.pkl           # ~25 KB
â”‚   â”œâ”€â”€ random_forest_model.pkl           # ~3 MB
â”‚   â”œâ”€â”€ svm_model.pkl                     # ~315 KB
â”‚   â”œâ”€â”€ label_encoder.pkl
â”‚   â”œâ”€â”€ scaler_standard.pkl
â”‚   â””â”€â”€ scaler_minmax.pkl
â”‚
â”œâ”€â”€ ğŸŒ webapp/                             # Flask Application (planned)
â”‚   â”œâ”€â”€ templates/                         # HTML templates (empty)
â”‚   â””â”€â”€ static/                            # CSS, JS, images (empty)
â”‚       â”œâ”€â”€ css/
â”‚       â”œâ”€â”€ js/
â”‚       â””â”€â”€ images/
â”‚
â”œâ”€â”€ ğŸ“„ docs/                               # Documentation (planned)
â”‚   â”œâ”€â”€ presentation/
â”‚   â”œâ”€â”€ project_report/
â”‚   â””â”€â”€ user_manual/
â”‚
â”œâ”€â”€ ğŸ§ª tests/                              # Unit tests (planned)
â”œâ”€â”€ âš™ï¸ config/                             # Configuration (planned)
â”‚
â”œâ”€â”€ ğŸ“ README.md                           # This file
â”œâ”€â”€ ğŸ“¦ requirements.txt                    # Python dependencies
â”œâ”€â”€ ğŸ““ app.ipynb                           # Additional notebook
â””â”€â”€ ğŸ“„ LICENSE                             # MIT License
```

---

## ğŸ“Š Datasets

### Primary Dataset: Crop Recommendation
| Attribute | Details |
|-----------|---------|
| **Source** | [Kaggle - Crop Recommendation Dataset](https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset) |
| **Size** | 2,200 rows Ã— 8 columns |
| **Features** | N, P, K, temperature, humidity, pH, rainfall |
| **Target** | label (22 crop types) |

### Feature Descriptions

| Feature | Description | Range |
|---------|-------------|-------|
| **N** | Nitrogen content in soil (kg/ha) | 0-140 |
| **P** | Phosphorus content in soil (kg/ha) | 5-145 |
| **K** | Potassium content in soil (kg/ha) | 5-205 |
| **temperature** | Average temperature (Â°C) | 8.8-43.7 |
| **humidity** | Relative humidity (%) | 14.3-100 |
| **ph** | Soil pH value | 3.5-10 |
| **rainfall** | Annual rainfall (mm) | 20.2-298.6 |

### Supported Crops (22 Classes)

```
apple, banana, blackgram, chickpea, coconut, coffee, cotton, 
grapes, jute, kidneybeans, lentil, maize, mango, mothbeans, 
mungbean, muskmelon, orange, papaya, pigeonpeas, pomegranate, 
rice, watermelon
```

### Additional Datasets

| Dataset | Size | Description |
|---------|------|-------------|
| `rotation_rules.csv` | 343 rows | Crop rotation compatibility rules |
| `Crop and fertilizer dataset.csv` | 377 KB | Extended fertilizer information |
| `crop-area-and-production.xlsx` | 40 KB | Historical production data |
| `Season_Price_Arrival_*.csv` | ~2 KB each | Market price data |

---

## ğŸ† Model Performance

### Model Comparison Summary

| Model | Test Accuracy | Precision | Recall | F1-Score | Overfitting Gap |
|-------|---------------|-----------|--------|----------|-----------------|
| **Random Forest** ğŸ¥‡ | **99.32%** | 99.35% | 99.32% | 99.32% | 0.57% |
| **SVM (RBF)** ğŸ¥ˆ | 97.95% | 98.09% | 97.95% | 97.94% | 1.48% |
| **Logistic Regression** ğŸ¥‰ | 97.73% | 97.93% | 97.73% | 97.71% | 1.14% |
| **Decision Tree** | 95.68% | 95.92% | 95.68% | 95.70% | 1.88% |

### Best Model: Random Forest
- **Configuration**: 100 estimators, max_depth=None
- **Accuracy**: 99.32% (test set)
- **Key Features**: pH, Potassium (K), Humidity

### SVM Model Details
- **Kernel**: RBF (Radial Basis Function)
- **C Parameter**: 100
- **Support Vectors**: 646 (36.7% of training data)
- **Accuracy**: 97.95%

### Training Performance

| Model | Training Time | Prediction Time (per sample) | Model Size |
|-------|---------------|------------------------------|------------|
| Decision Tree | 0.02s | 0.004ms | 25 KB |
| Logistic Regression | 0.20s | 0.003ms | 8 KB |
| Random Forest | 0.38s | 0.257ms | 3 MB |
| SVM | 20.88s | 0.182ms | 315 KB |

---

## ğŸš€ Installation

### Prerequisites
- Python 3.10 or higher
- pip package manager
- Git (optional)

### Step 1: Clone the Repository
```bash
git clone https://github.com/yourusername/crop-recommendation-system.git
cd crop-recommendation-system
```

### Step 2: Create Virtual Environment
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/macOS
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Launch Jupyter Notebook
```bash
jupyter notebook
```

---

## ğŸ“– Usage

### Running the Notebooks

Execute notebooks in order for the complete pipeline:

```bash
# 1. Data Loading
jupyter notebook notebooks/01_Data_Collection_and_Loading.ipynb

# 2. Data Cleaning
jupyter notebook notebooks/2.Data_Cleaning_and_Preprocessing.ipynb

# 3. EDA
jupyter notebook notebooks/3.Exploratory_Data_Analysis.ipynb

# Continue with remaining notebooks...
```

### Using Trained Models

```python
import pickle
import numpy as np

# Load the best model (Random Forest)
with open('models/random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Load the scaler
with open('models/scaler_standard.pkl', 'rb') as f:
    scaler = pickle.load(f)

# Load label encoder
with open('models/label_encoder.pkl', 'rb') as f:
    label_encoder = pickle.load(f)

# Example prediction
# Features: N, P, K, temperature, humidity, pH, rainfall (+ engineered features)
sample_input = np.array([[90, 42, 43, 20.87, 82.00, 6.50, 202.93]])  
# Note: Full feature engineering needed for 39 features

# Predict
prediction = model.predict(sample_input)
crop_name = label_encoder.inverse_transform(prediction)
print(f"Recommended Crop: {crop_name[0]}")
```

---

## ğŸ““ Notebooks Guide

### Phase 1: Data Preparation (Notebooks 1-5)

| # | Notebook | Description | Key Outputs |
|---|----------|-------------|-------------|
| 1 | Data Collection | Load raw datasets | `crop_data_loaded.csv` |
| 2 | Data Cleaning | Handle missing values, outliers | `crop_data_cleaned.csv` |
| 3 | EDA | 43 visualizations, statistics | `visualizations/*.png` |
| 4 | Feature Engineering | Create 39 features | `crop_data_engineered.csv` |
| 5 | Train-Test Split | Prepare ML-ready data | `ml_ready/*.npy` |

### Phase 2: Model Training (Notebooks 6-9)

| # | Notebook | Algorithm | Accuracy | Status |
|---|----------|----------|----------|--------|
| 6 | Logistic Regression | Linear classifier | 97.73% | âœ… Complete |
| 7 | Decision Tree | Tree-based classifier | 95.68% | âœ… Complete |
| 8 | Random Forest | Ensemble (bagging) | 99.32% | âœ… Complete |
| 9 | SVM | Support Vector Machine | 97.95% | âœ… Complete |

### Phase 3: Advanced Models (Planned)

| # | Notebook | Algorithm | Status |
|---|----------|----------|--------|
| 10 | XGBoost & LightGBM | Gradient boosting | â³ Planned |
| 11 | Stacking Ensemble | Meta-learner | â³ Planned |
| 12 | Model Comparison | Final selection | â³ Planned |
| 13 | SHAP Explainability | XAI visualizations | â³ Planned |
| 14 | Economic Analysis | ROI calculations | â³ Planned |
| 15 | Crop Rotation | Multi-season planning | â³ Planned |
| 16 | Final Pipeline | Deployment ready | â³ Planned |

---

## ğŸ“ˆ Visualizations Generated

### EDA Visualizations (1-23)
- Feature distributions (histograms, boxplots)
- Correlation heatmap
- Pairplot of all features
- Crop distribution analysis
- Violin plots by crop
- 3D NPK scatter plot
- Climate zone analysis

### Model Performance Visualizations (24-43)
- Confusion matrices (raw and normalized)
- Per-class performance (Precision, Recall, F1)
- Feature importance charts
- Confidence distribution plots
- Decision tree structure
- Support vectors analysis (SVM)

---

## ğŸ—ºï¸ Future Roadmap

### Short-term Goals
- [ ] Implement XGBoost and LightGBM models
- [ ] Create Stacking Ensemble for improved accuracy
- [ ] Add SHAP explainability module
- [ ] Build Flask web application

### Medium-term Goals
- [ ] Implement economic viability analysis
- [ ] Add crop rotation planning module
- [ ] Create REST API for predictions
- [ ] Deploy to cloud platform

### Long-term Goals
- [ ] Mobile application development
- [ ] Real-time weather data integration
- [ ] Regional customization (India-specific)
- [ ] Multi-language support

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Prathamesh Gawas**

- GitHub: [@prathameshgawas](https://github.com/prathameshgawas)

---

## ğŸ™ Acknowledgments

- [Kaggle](https://www.kaggle.com/) for the Crop Recommendation Dataset
- [scikit-learn](https://scikit-learn.org/) for ML algorithms
- [Government of India - Agmarknet](https://agmarknet.gov.in/) for market price data
- [ICAR](https://icar.org.in/) for crop rotation research

---

<p align="center">
  <b>â­ Star this repository if you found it helpful! â­</b>
</p>
